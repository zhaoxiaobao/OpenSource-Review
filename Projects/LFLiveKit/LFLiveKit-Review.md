# LFLiveKit-Review  

> ä¹‹å‰é¡¹ç›®ç”¨åˆ°LFLiveKitï¼Œç°åœ¨æœ‰ç©ºæ¥å†™ç¯‡åˆ†ææºç çš„æ–‡ç« ã€‚

## LFLiveKitæ¶æ„å›¾è§£
LFLiveKitå·¥ç¨‹æ–‡ä»¶å·²ç»æ¯”è¾ƒæ¸…æ™°äº†ï¼Œæ•´ç†å¦‚ä¸‹ï¼š
<p align="center">
  <img src="https://raw.githubusercontent.com/zhaoxiaobao/OpenSource-Review/master/Projects/Images/LFLiveKit.png" alt="img"/>
</p>

> å•§å•§å•§ï¼Œè¿™ä¸ªå›¾åŸºæœ¬ä¸Šå°±æ˜¯æ¥ç–¯kitå·¥ç¨‹çš„ç›®å½•å›¾ï¼Œä¸ªäººè§‰å¾—è¿˜æ˜¯å¾ˆğŸ‘çš„ï¼Œä½ ä»¬å¯ä»¥followè¿™ä½ä½œè€…[chenliming777](https://github.com/chenliming777)ã€‚å¾€ä¸‹ğŸ±ä¸‹ï¼Œå’±è¿›å…¥æ­£é¢˜ã€‚ç»Ÿè®¡ä¸€ä¸‹LFLiveKitçš„ä»£ç è¡Œï¼Œåœ¨3664è¡Œå·¦å³ã€‚ç»Ÿè®¡è„šæœ¬å¦‚ä¸‹ï¼š

```ruby
find . "(" -name "*.m" -or -name "*.mm" -or -name "*.cpp" -or -name "*.h" -or -name "*.rss" ")" -print | xargs wc -l
```

## æºç åˆ†æ
### ä»è¿™åˆå§‹åŒ–æ–¹æ³•è¯´èµ·  

``` ruby

_session = [[LFLiveSession alloc] initWithAudioConfiguration:[LFLiveAudioConfiguration defaultConfiguration]
                                          videoConfiguration:[LFLiveVideoConfiguration defaultConfigurationForQuality:LFLiveVideoQuality_Medium2 landscape:NO]];

```
å½“åˆ›å»ºè¿™ä¸ªsessionæ—¶å€™ï¼Œåšäº†è¿™å‡ ä»¶äº‹æƒ…ï¼š
   1. åˆå§‹åŒ–éŸ³é¢‘é…ç½®

     ```ruby
     /// é»˜è®¤éŸ³é¢‘é…ç½®
     + (instancetype)defaultConfiguration;
     +(instancetype)defaultConfigurationForQuality:(LFLiveAudioQuality)audioQuality;
     ```

   2. åˆå§‹åŒ–è§†é¢‘é…ç½®

   ```ruby
   /// é»˜è®¤è§†é¢‘é…ç½®
    + (instancetype)defaultConfiguration;
   /// è§†é¢‘é…ç½®(è´¨é‡)
   +(instancetype)defaultConfigurationForQuality:(LFLiveVideoQuality)videoQuality;
   /// è§†é¢‘é…ç½®(è´¨é‡ & æ˜¯å¦æ˜¯æ¨ªå±)
   +(instancetype)defaultConfigurationForQuality:(LFLiveVideoQuality)videoQuality landscape:(BOOL)landscape;
   ```

   åˆå§‹åŒ–sessionæ—¶å€™éœ€è¦é…ç½®ç›¸å…³éŸ³è§†é¢‘å‚æ•°ï¼Œæ¥ä¸‹æ¥æˆ‘ä»¬æ¥åˆ†æçœ‹çœ‹LFLiveKitæ˜¯å¦‚ä½•è¿›è¡ŒéŸ³è§†é¢‘é‡‡é›†çš„ã€‚

### éŸ³è§†é¢‘é‡‡é›†
LFLiveKitéŸ³é¢‘é‡‡é›†æ˜¯é€šè¿‡ç³»ç»ŸAVAudioUnitè¿›è¡ŒéŸ³é¢‘é‡‡é›†çš„ï¼ŒLFLiveKitå¯¹éŸ³é¢‘é‡‡é›†æ²¡æœ‰åšä»€ä¹ˆç‰¹åˆ«çš„å¤„ç†ï¼Œä¹‹å‰é‡åˆ°é™å™ªç®—æ³•å¤„ç†ï¼Œåæ¥googleä¹‹ï¼Œå‘ç°iphoneç³»ç»Ÿæœ¬èº«å°±å¯¹éŸ³é¢‘è¿›è¡Œé™å™ªå¤„ç†ã€‚å¦‚æœåæœŸåŠ å…¥ç¾å£°ï¼Œå˜å£°ä¹‹ç±»å¯¹éŸ³é¢‘å¤„ç†éœ€è¦åœ¨LFAudioCaptureä¸­å®Œå–„ingã€‚å¦‚ä¸‹è´´å‡ºé‡‡é›†ä»£ç :

```ruby  
AVAudioSession *session = [AVAudioSession sharedInstance];
....
....
AudioComponentDescription acd;
  acd.componentType = kAudioUnitType_Output;
  acd.componentSubType = kAudioUnitSubType_RemoteIO;
  acd.componentManufacturer = kAudioUnitManufacturer_Apple;
  acd.componentFlags = 0;
  acd.componentFlagsMask = 0;
  self.component = AudioComponentFindNext(NULL, &acd);


```
> è¿™é‡Œä»‹ç»ä¸€ä¸‹AVAudioSessionï¼Œæ¥è‡ªå®˜æ–¹çš„è§£é‡Šæ˜¯An audio session is a singleton object that you employ to set the audio context for your app and to express to the system your intentions for your appâ€™s audio behavior. å°±æ˜¯è¯´å‘Šè¯‰ç³»ç»Ÿåº”ç”¨ç¨‹åºä½¿ç”¨éŸ³é¢‘çš„æƒ…å†µã€‚è¿™é‡Œå¯èƒ½å°±ä¼šæ¶‰åŠéŸ³é¢‘è¢«å…¶ä»–ç¨‹åºå ç”¨çš„æƒ…å†µï¼Œæ¯”å¦‚æœ‰å¾®ä¿¡è§†é¢‘èŠå¤©æŠ¢å éŸ³é¢‘ï¼ŒéŸ³é¢‘æ¢å¤ä¸è¿‡æ¥ã€‚ä½œè€…é€šè¿‡è¿™ä¸¤è¡Œä»£ç æ¥è§£å†³ï¼š

```
[[AVAudioSession sharedInstance] setCategory:AVAudioSessionCategoryPlayAndRecord error:nil];
[[AVAudioSession sharedInstance] setActive:YES error:nil];
```
LFLiveKitéŸ³é¢‘é€šè¿‡AURenderCallbackStructè¿›è¡Œå›è°ƒå¤„ç†é‡‡é›†éŸ³é¢‘æ•°æ®ï¼Œè¿™é‡Œå–å‡ºå›è°ƒå‡½æ•°çš„å‚æ•°
```ruby
static OSStatus handleInputBuffer(void *inRefCon,
                                  AudioUnitRenderActionFlags *ioActionFlags,
                                  const AudioTimeStamp *inTimeStamp,
                                  UInt32 inBusNumber,
                                  UInt32 inNumberFrames,
                                  AudioBufferList *ioData) {
                                    ......
                                    ......
                                    ..
                                  }

```
> åœ¨handleInputBufferé€šè¿‡[source.delegate captureOutput:source audioBuffer:buffers]ä»£ç†ï¼Œåœ¨LFLiveSessionä¸­å°†éŸ³é¢‘è¿›è¡Œç¼–ç ã€‚


LFLiveKitè§†é¢‘é‡‡é›†æ˜¯é€šè¿‡GPUImageVideoCameraè¿›è¡Œè§†é¢‘é‡‡é›†çš„ï¼Œç¾é¢œæ»¤é•œåŠŸèƒ½ä¹Ÿæ˜¯åŸºäºGPUImageï¼Œå…·ä½“ç¾é¢œç®—æ³•è¿˜å¾…æ·±ç©¶ã€‚

```ruby
_videoCamera = [[GPUImageVideoCamera alloc] initWithSessionPreset:_configuration.avSessionPreset cameraPosition:AVCaptureDevicePositionFront];

```
åŠ ä¸Šfilleré€šè¿‡GPUImageOutè¿›è¡Œå›è°ƒï¼Œè¿™é‡Œæ¶‰åŠä¸¤ä¸ªå‚æ•°ä¸€ä¸ªæ˜¯outputï¼Œä¸€ä¸ªæ˜¯æ—¶é—´æˆ³ã€‚

```ruby
#pragma mark -- Custom Method
- (void) processVideo:(GPUImageOutput *)output{
    __weak typeof(self) _self = self;
    @autoreleasepool {
        GPUImageFramebuffer *imageFramebuffer = output.framebufferForOutput;
        //CVPixelBufferRef pixelBuffer = [imageFramebuffer pixelBuffer];

        size_t width = imageFramebuffer.size.width;
        size_t height = imageFramebuffer.size.height;
        ///< è¿™é‡Œå¯èƒ½ä¼šå½±å“æ€§èƒ½ï¼Œä»¥åè¦å°è¯•ä¿®æ”¹GPUImageæºç  ç›´æ¥è·å–CVPixelBufferRef ç›®å‰æ˜¯è·å–çš„bytes å…¶å®æ›´éº»çƒ¦äº†
        if(imageFramebuffer.size.width == 360){
            width = 368;///< å¿…é¡»è¢«16æ•´é™¤
        }

        CVPixelBufferRef pixelBuffer = NULL;
        CVPixelBufferCreateWithBytes(kCFAllocatorDefault, width, height, kCVPixelFormatType_32BGRA, [imageFramebuffer byteBuffer], width * 4, nil, NULL, NULL, &pixelBuffer);

        if(pixelBuffer && _self.delegate && [_self.delegate respondsToSelector:@selector(captureOutput:pixelBuffer:)]){
            [_self.delegate captureOutput:_self pixelBuffer:pixelBuffer];
        }
        CVPixelBufferRelease(pixelBuffer);

    }
}

```
> è¿™é‡Œè¾¹éœ€è¦ç‰¹åˆ«å…³æ³¨ä¸€ä¸‹CVPixelBufferRefå…¨ç§°æ˜¯Core Video pixel bufferï¼Œå…¶å®è¯´ç™½äº†å°±æ˜¯ç¼“å­˜çš„ä¸€å¸§å›¾ç‰‡ã€‚è¿™æ˜¯å®˜æ–¹çš„è§£é‡ŠA Core Video pixel buffer is an image buffer that holds pixels in main memory. Applications generating frames, compressing or decompressing video, or using Core Image can all make use of Core Video pixel buffers. ä¹‹å‰æ²¡æ¥è§¦è¿‡ï¼Œæ‰€ä»¥markä¸‹ã€‚

æ•°æ®é‡‡é›†å®Œæ¯•ä¹‹åé€šè¿‡CaptureDelegateä»£ç†åœ¨LFLiveSessionä¸­å°†ç¼“å­˜å›¾ç‰‡è¿›è¡Œç¼–ç ï¼Œç¼–ç æ¶‰åŠä¸¤é‡è¦çš„å‚æ•°ï¼Œä¸€ä¸ªpixelBufferï¼Œä¸€ä¸ªtimeStampï¼Œå…¶å®å°±æ˜¯é‡‡é›†æ—¶å€™é‚£ä¸¤ä¸ªå‚æ•°ï¼Œæ¥ä¸‹æ¥ä»‹ç»ç¼–ç ã€‚

### éŸ³è§†é¢‘ç¼–ç 
å¦‚ä¸‹åœ¨LFLiveSessionä¸¤ä¸ªä»£ç†æ–¹æ³•ï¼š
```ruby
- (void)captureOutput:(nullable LFAudioCapture*)capture audioBuffer:(AudioBufferList)inBufferList{
    [self.audioEncoder encodeAudioData:inBufferList timeStamp:self.currentTimestamp];
}
- (void)captureOutput:(nullable LFVideoCapture*)capture pixelBuffer:(nullable CVImageBufferRef)pixelBuffer{
    [self.videoEncoder encodeVideoData:pixelBuffer timeStamp:self.currentTimestamp];
}
```
æ¥ç€å¾€ä¸‹è¾¹çœ‹éŸ³é¢‘ç¡¬ç¼–ç ï¼š
```ruby
- (void)encodeAudioData:(AudioBufferList)inBufferList timeStamp:(uint64_t)timeStamp{
    if (![self createAudioConvert]){
        return;
    }
    if(!aacBuf){
        aacBuf = malloc(inBufferList.mBuffers[0].mDataByteSize);
    }

    // åˆå§‹åŒ–ä¸€ä¸ªè¾“å‡ºç¼“å†²åˆ—è¡¨
    AudioBufferList outBufferList;
    outBufferList.mNumberBuffers              = 1;
    outBufferList.mBuffers[0].mNumberChannels = inBufferList.mBuffers[0].mNumberChannels;
    outBufferList.mBuffers[0].mDataByteSize   = inBufferList.mBuffers[0].mDataByteSize; // è®¾ç½®ç¼“å†²åŒºå¤§å°
    outBufferList.mBuffers[0].mData           = aacBuf; // è®¾ç½®AACç¼“å†²åŒº
    UInt32 outputDataPacketSize               = 1;
    if (AudioConverterFillComplexBuffer(m_converter, inputDataProc, &inBufferList, &outputDataPacketSize, &outBufferList, NULL) != noErr){
        return;
    }
    LFAudioFrame *audioFrame = [LFAudioFrame new];
    audioFrame.timestamp = timeStamp;
    audioFrame.data = [NSData dataWithBytes:aacBuf length:outBufferList.mBuffers[0].mDataByteSize];

    char exeData[2];
    exeData[0] = _configuration.asc[0];
    exeData[1] = _configuration.asc[1];
    audioFrame.audioInfo =[NSData dataWithBytes:exeData length:2];
    if(self.aacDeleage && [self.aacDeleage respondsToSelector:@selector(audioEncoder:audioFrame:)]){
        [self.aacDeleage audioEncoder:self audioFrame:audioFrame];
    }
}
```
éŸ³é¢‘ç¼–ç è¿‡ç¨‹åšäº†å¦‚ä¸‹å‡ ä»¶äº‹ï¼š
    1. å°†éŸ³é¢‘ç¼–ç æˆAACæ ¼å¼ï¼Œç¼–ç æ ·å¼åœ¨LFAudioFrameä¸­ï¼Œå¯ç¼–è¾‘audioInfoåœ¨flvæ‰“åŒ…ä¸­AACçš„headerã€‚
    2. ç¼–ç å®Œæˆå°†æ•°æ®ä¸Šä¼ ã€‚

> é€šè¿‡[self.aacDeleage audioEncoder:self audioFrame:audioFrame];å°†æ‰“åŒ…å¥½çš„éŸ³é¢‘æ•°æ®ä¸Šä¼ ï¼Œä¸Šä¼ æ¥ä¸‹æ¥åˆ†æã€‚

æ¥ç€å¾€ä¸‹è¾¹çœ‹è§†é¢‘ç¡¬ç¼–ç ï¼š
```ruby
#pragma mark -- LFVideoEncoder
- (void)encodeVideoData:(CVImageBufferRef)pixelBuffer timeStamp:(uint64_t)timeStamp{
    if(_isBackGround) return;
    frameCount ++;
    CMTime presentationTimeStamp = CMTimeMake(frameCount, 1000);
    VTEncodeInfoFlags flags;
    CMTime duration = CMTimeMake(1, (int32_t)_configuration.videoFrameRate);
    NSDictionary *properties = nil;
    if(frameCount % (int32_t)_configuration.videoMaxKeyframeInterval == 0){
        properties = @{(__bridge NSString *)kVTEncodeFrameOptionKey_ForceKeyFrame: @YES};
    }
    NSNumber *timeNumber = @(timeStamp);
    VTCompressionSessionEncodeFrame(compressionSession, pixelBuffer, presentationTimeStamp, duration, (__bridge CFDictionaryRef)properties, (__bridge_retained void *)timeNumber, &flags);
}

```
> è§†é¢‘ç¼–ç ç›´æ¥é€šè¿‡VideoToolboxè¿›è¡Œç¡¬ç¼–ï¼Œè¿™ä¸ªç³»ç»Ÿæä¾›äº†æ”¯æŒï¼Œç›¸å¯¹ç®€æ˜“äº†è®¸å¤šã€‚ä¹‹å‰æ¥è§¦videocoreï¼Œæ¶‰åŠffmpegè½¯ç¼–ç ï¼Œä¸çŸ¥é“è¿™ä¸¤è€…æ•ˆç‡æ€ä¹ˆæ ·ã€‚
VTCompressionSessionRefä¸­æœ‰ä¸ªVideoCallBackå›è°ƒï¼Œä»£ç å¦‚ä¸‹ï¼Œç®€æ˜“æ³¨é‡Šäº†ä¸‹

```ruby
static void VideoCompressonOutputCallback(void *VTref, void *VTFrameRef, OSStatus status, VTEncodeInfoFlags infoFlags, CMSampleBufferRef sampleBuffer){

  //ç¼–ç å®Œäº†ä¹‹å
  //å›è°ƒ....ä¸Šä¼ ing

}

```
è¿™ä¸ªæ–¹æ³•ä»£ç æœ‰ç‚¹å¤šï¼Œæ”¾åœ¨gistä¸Š[æˆ³ä¸‹çœ‹çœ‹](https://gist.github.com/zhaoxiaobao/6322b0fb2fdc8467100284df4bf31253)ã€‚è¿™ä¸ªåœ°æ–¹è¿˜æœ‰å¾ˆå¤šè¦è¯´çš„ï¼Œè¿˜åœ¨æŒ–å‘ingï¼ï¼ï¼


### ä¸Šä¼ éŸ³è§†é¢‘æ•°æ®
```ruby
#pragma mark -- EncoderDelegate
- (void)audioEncoder:(nullable id<LFAudioEncoding>)encoder audioFrame:(nullable LFAudioFrame*)frame{
    if(self.uploading) [self.socket sendFrame:frame];//<ä¸Šä¼ 
}

- (void)videoEncoder:(nullable id<LFVideoEncoding>)encoder videoFrame:(nullable LFVideoFrame*)frame{
    if(self.uploading) [self.socket sendFrame:frame];//<ä¸Šä¼ 
}

#pragma mark -- LFStreamTcpSocketDelegate
- (void)socketStatus:(nullable id<LFStreamSocket>)socket status:(LFLiveState)status{
    if(status == LFLiveStart){
        if(!self.uploading){
            self.timestamp = 0;
            self.isFirstFrame = YES;
            self.uploading = YES;
        }
    }
    dispatch_async(dispatch_get_main_queue(), ^{
        self.state = status;
        if(self.delegate && [self.delegate respondsToSelector:@selector(liveSession:liveStateDidChange:)]){
            [self.delegate liveSession:self liveStateDidChange:status];
        }
    });
}
```
> ä¸Šä¼ æ•°æ®ä¹‹å‰ç”¨librtmp-iOSï¼Œåæ¥æ”¹ç”¨pili-librtmpï¼Œç–‘ä¼¼è¿˜æœ‰å°bugï¼Œå¯èƒ½å’ŒæœåŠ¡å™¨æœ‰å…³ã€‚

## ç»“å°¾
å¸Œæœ›å¯¹å¤§å®¶å¸®åŠ©
